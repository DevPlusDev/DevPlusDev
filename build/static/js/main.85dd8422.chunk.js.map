{"version":3,"sources":["settings.js","Controls.js","Video.js","VideoCall.js","App.js","index.js"],"names":["config","mode","codec","appId","token","useClient","createClient","useMicrophoneAndCameraTracks","createMicrophoneAndCameraTracks","channelName","Controls","props","client","tracks","setStart","setInCall","useState","video","audio","trackState","setTrackState","mute","type","setEnabled","ps","leaveChannel","leave","removeAllListeners","close","Grid","container","spacing","alignItems","item","Button","variant","color","onClick","Video","users","gridSpacing","setGridSpacing","useEffect","Math","max","floor","length","style","height","xs","videoTrack","width","map","user","console","log","uid","VideoCall","setUsers","start","ready","init","name","on","mediaType","subscribe","prevUsers","audioTrack","play","stop","filter","User","join","publish","error","direction","App","inCall","className","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"kOAKaA,EAAS,CAClBC,KAAM,MACNC,MAAO,MACPC,MANU,mCAOVC,MANU,mJAQDC,EAAYC,uBAAaN,GACzBO,EAA+BC,4CAC/BC,EAAc,O,6GCDZ,SAASC,EAASC,GAC/B,IAAMC,EAASP,IACPQ,EAAgCF,EAAhCE,OAAQC,EAAwBH,EAAxBG,SAAUC,EAAcJ,EAAdI,UAE1B,EAAoCC,mBAAS,CAAEC,OAAO,EAAMC,OAAO,IAAO,mBAAnEC,EAAU,KAAEC,EAAa,KAE1BC,EAAI,iDAAG,WAAOC,GAAI,8EAET,UAATA,EAAgB,gCAEZT,EAAO,GAAGU,YAAYJ,EAAWD,OAAO,KAAD,EAE7CE,GAAc,SAACI,GACb,OAAO,2BAAKA,GAAE,IAAEN,OAAQM,EAAGN,OAC7B,IACA,0BACkB,UAATI,EAAgB,iCACnBT,EAAO,GAAGU,YAAYJ,EAAWF,OAAO,KAAD,EAC7CG,GAAc,SAACI,GACb,OAAO,2BAAKA,GAAE,IAAEP,OAAQO,EAAGP,OAC7B,IAAG,4CAEN,gBAhBS,sCAmBJQ,EAAY,iDAAG,wGAEbb,EAAOc,QAAQ,KAAD,EAEpBd,EAAOe,qBAEPd,EAAO,GAAGe,QACVf,EAAO,GAAGe,QAEVd,GAAS,GACTC,GAAU,GAAO,2CAClB,kBAXiB,mCAalB,OAEE,cADA,CACCc,EAAA,EAAI,CAACC,WAAS,EAACC,QAAS,EAAGC,WAAW,SAAQ,UAC7C,cAACH,EAAA,EAAI,CAACI,MAAI,WACR,cAACC,EAAA,EAAM,CACLC,QAAQ,YAERC,MAAOjB,EAAWD,MAAQ,UAAY,YAEtCmB,QAAS,kBAAMhB,EAAK,QAAQ,EAAC,SAG5BF,EAAWD,MAAQ,cAAC,IAAO,IAAM,cAAC,IAAU,QAGjD,cAACW,EAAA,EAAI,CAACI,MAAI,WAER,cAACC,EAAA,EAAM,CACLC,QAAQ,YACRC,MAAOjB,EAAWF,MAAQ,UAAY,YACtCoB,QAAS,kBAAMhB,EAAK,QAAQ,EAAC,SAE5BF,EAAWF,MAAQ,cAAC,IAAY,IAAM,cAAC,IAAe,QAG3D,cAACY,EAAA,EAAI,CAACI,MAAI,WAER,eAACC,EAAA,EAAM,CACLC,QAAQ,YACRC,MAAM,UACNC,QAAS,kBAAMZ,GAAc,EAAC,kBAG9B,cAAC,IAAa,WAKxB,CClFe,SAASa,EAAM3B,GAC5B,IAAQ4B,EAAkB5B,EAAlB4B,MAAO1B,EAAWF,EAAXE,OAEf,EAAsCG,mBAAS,IAAG,mBAA3CwB,EAAW,KAAEC,EAAc,KASlC,OANAC,qBAAU,WAERD,EAAeE,KAAKC,IAAID,KAAKE,MAAM,IAAMN,EAAMO,OAAS,IAAK,GAE/D,GAAG,CAACP,EAAO1B,IAIT,cADA,CACCgB,EAAA,EAAI,CAACC,WAAS,EAACiB,MAAO,CAAEC,OAAQ,QAAS,UAExC,cAACnB,EAAA,EAAI,CAACI,MAAI,EAACgB,GAAIT,EAAY,SAEzB,cAAC,mBAAgB,CACfU,WAAYrC,EAAO,GACnBkC,MAAO,CAAEC,OAAQ,OAAQG,MAAO,YAInCZ,EAAMO,OAAS,GACdP,EAAMa,KAAI,SAACC,GAET,OADAC,QAAQC,IAAI,cAAeF,GACvBA,EAAKH,WAEL,cAACrB,EAAA,EAAI,CAACI,MAAI,EAACgB,GAAIT,EAAY,SACzB,cAAC,mBAAgB,CACfU,WAAYG,EAAKH,WAEjBH,MAAO,CAAEC,OAAQ,OAAQG,MAAO,SAD3BE,EAAKG,OAMJ,IAChB,MAGR,CCzCe,SAASC,EAAU9C,GAC9B,IAAQI,EAAcJ,EAAdI,UACR,EAA4BC,mBAAS,IAAG,mBAAhCuB,EAAK,KAAEmB,EAAQ,KACvB,EAA4B1C,oBAAS,GAAM,mBAAnC2C,EAAK,KAAE7C,EAAQ,KAGjBF,EAASP,IAEf,EAA0BE,IAAlBqD,EAAK,EAALA,MAAO/C,EAAM,EAANA,OAgEf,OA9DA6B,qBAAU,WACN,IAAImB,EAAI,iDAAG,WAAOC,GAAI,2EAoCf,OAjCHlD,EAAOmD,GAAG,iBAAgB,iDAAE,WAAMV,EAAMW,GAAS,2FACvCpD,EAAOqD,UAAUZ,EAAMW,GAAW,KAAD,EACrB,UAAdA,GAEAN,GAAS,SAACQ,GACN,MAAM,GAAN,mBAAWA,GAAS,CAAEb,GAC1B,IAGc,UAAdW,GACAX,EAAKc,WAAWC,OAClB,2CACL,qDAZyB,IAe1BxD,EAAOmD,GAAG,oBAAoB,SAACV,EAAMW,GACf,UAAdA,GACGX,EAAKc,YAAYd,EAAKc,WAAWE,OAEtB,UAAdL,GAEAN,GAAS,SAACQ,GAEN,OAAOA,EAAUI,QAAO,SAACC,GAAI,OAAKA,EAAKf,MAAQH,EAAKG,GAAG,GAC3D,GAER,IAEA5C,EAAOmD,GAAG,aAAa,SAACV,GAEpBK,GAAS,SAACQ,GACF,OAAOA,EAAUI,QAAO,SAACC,GAAI,OAAKA,EAAKf,MAAQH,EAAKG,GAAG,GAC3D,GACR,IAAG,kBAIO5C,EAAO4D,KAAKxE,EAAOG,MAAO2D,EAAM9D,EAAOI,MAAO,MAAM,KAAD,kDAEzDkD,QAAQC,IAAI,UAAD,cAAmB,YAI9B1C,EAAO,CAAD,iCAAQD,EAAO6D,QAAQ5D,EAAO,GAAIA,EAAO,IAAI,KAAD,GACtDC,GAAS,GAAM,yDAClB,gBAhDO,sCAkDR,GAAI8C,GAAS/C,EACT,IAEIgD,EAAKpD,EAGT,CAFE,MAAOiE,GACLpB,QAAQC,IAAI,UAAD,OAAWmB,GAC1B,CAGR,GAAG,CAACjE,EAAaG,EAAQgD,EAAO/C,IAI5B,cADA,CACCgB,EAAA,EAAI,CAACC,WAAS,EAAC6C,UAAU,SAAS5B,MAAO,CAAEC,OAAQ,QAAS,UAEzD,cAACnB,EAAA,EAAI,CAACI,MAAI,EAACc,MAAO,CAAEC,OAAQ,MAAO,SAE9BY,GAAS/C,GAAW,cAACH,EAAQ,CAACG,OAAQA,EAAQC,SAAU6C,EAAO5C,UAAWA,MAI9E,cAACc,EAAA,EAAI,CAACI,MAAI,EAACc,MAAO,CAAEC,OAAQ,OAAQ,SAEhCW,GAAS9C,GAAW,cAACyB,EAAK,CAACzB,OAAQA,EAAQ0B,MAAOA,QAKnE,CCtEeqC,MArBf,WACE,MAA4B5D,oBAAS,GAAM,mBAApC6D,EAAM,KAAE9D,EAAS,KAExB,OACE,qBAAK+D,UAAU,MAAM/B,MAAO,CAAEC,OAAQ,QAAS,SAE5C6B,EACC,cAACpB,EAAS,CAAC1C,UAAWA,IAEtB,cAACmB,EAAA,EAAM,CACLC,QAAQ,YACRC,MAAM,UACNC,QAAS,kBAAMtB,GAAU,EAAK,EAAC,wBAOzC,ECnBAgE,IAASC,OACP,cAAC,IAAMC,WAAU,UACf,cAAC,EAAG,MAENC,SAASC,eAAe,Q","file":"static/js/main.85dd8422.chunk.js","sourcesContent":["import { createClient, createMicrophoneAndCameraTracks } from \"agora-rtc-react\";\n\nconst appId = \"a0c5b211bfaa4092972eb225f76e13a7\";\nconst token = \"007eJxTYHDlr7N8tbP7/fnG82yHDgRpiT6buvWmYc99nz/zbF9L9PUoMCQaJJsmGRkaJqUlJpoYWBpZmhulJhkZmaaZm6UaGieay+U0JjcEMjJ4ft3MysgAgSA+C0NuYmYeAwMAyCYg6Q==\";\n\nexport const config = {\n    mode: \"rtc\",\n    codec: \"vp8\",\n    appId: appId,\n    token: token\n};\nexport const useClient = createClient(config);\nexport const useMicrophoneAndCameraTracks = createMicrophoneAndCameraTracks();\nexport const channelName = \"main\";","import React from \"react\";\nimport { useState } from \"react\";\nimport { useClient } from \"./settings\";\n\n// Import necessary styling components and designs from MaterialUI.\nimport { Grid, Button } from \"@material-ui/core\";\nimport MicIcon from \"@material-ui/icons/Mic\";\nimport MicOffIcon from \"@material-ui/icons/MicOff\";\nimport VideocamIcon from \"@material-ui/icons/Videocam\";\nimport VideocamOffIcon from \"@material-ui/icons/VideocamOff\";\nimport ExitToAppIcon from \"@material-ui/icons/ExitToApp\";\n\nexport default function Controls(props) {\n  const client = useClient();\n  const { tracks, setStart, setInCall } = props;\n\n  const [trackState, setTrackState] = useState({ video: true, audio: true });\n\n  const mute = async (type) => {\n    // Disable the audio track\n    if (type === \"audio\") {\n        // Change the state to the opposite of what the current state of audio is.\n      await tracks[0].setEnabled(!trackState.audio);\n      // Create the new state replacing the new audio state after muting.\n      setTrackState((ps) => {\n        return { ...ps, audio: !ps.audio };\n      });\n      // Video muting logic follows the audio logic as above\n    } else if (type === \"video\") {\n      await tracks[1].setEnabled(!trackState.video);\n      setTrackState((ps) => {\n        return { ...ps, video: !ps.video };\n      });\n    }\n  };\n\n\n  const leaveChannel = async () => {\n    // Client method to leave the channel with Agora.\n    await client.leave();\n    // All client.on() event listeners from VideoCall.js are removed.\n    client.removeAllListeners();\n    // Close the audio and video tracks.\n    tracks[0].close();\n    tracks[1].close();\n    // Change the state of the user being in the video call.\n    setStart(false);\n    setInCall(false);\n  };\n\n  return (\n    // This setups us a grid using MaterialUI with Flexbox under the hood. Three predominant grid items for the controls around video and audio.\n    <Grid container spacing={2} alignItems=\"center\">\n      <Grid item>\n        <Button\n          variant=\"contained\"\n          // Change the color of the button if the audio is on or if it is off.\n          color={trackState.audio ? \"primary\" : \"secondary\"}\n          // When the button is clicked then mute the audio or the video, whichever string is passed in.\n          onClick={() => mute(\"audio\")}\n        >\n        {/* Show a different icon for the microphone if the user is muted. */}\n          {trackState.audio ? <MicIcon /> : <MicOffIcon />}\n        </Button>\n      </Grid>\n      <Grid item>\n        {/* This button is the same as the above grid item, instead of for controlling audio it is controlling video and changing the icons based on the state of the user. */}\n        <Button\n          variant=\"contained\"\n          color={trackState.video ? \"primary\" : \"secondary\"}\n          onClick={() => mute(\"video\")}\n        >\n          {trackState.video ? <VideocamIcon /> : <VideocamOffIcon />}\n        </Button>\n      </Grid>\n      <Grid item>\n        {/* Button to leave the channel/video call. */}\n        <Button\n          variant=\"contained\"\n          color=\"default\"\n          onClick={() => leaveChannel()}\n        >\n          Leave\n          <ExitToAppIcon />\n        </Button>\n      </Grid>\n    </Grid>\n  );\n}","import React from \"react\";\n// Import the video player for the Agora wrapper that was installed.\nimport { AgoraVideoPlayer } from \"agora-rtc-react\";\nimport { Grid } from \"@material-ui/core\";\nimport { useState, useEffect } from \"react\";\n\nexport default function Video(props) {\n  const { users, tracks } = props;\n  // We need to change the spacing for each video panel of the person in the video call room.\n  const [gridSpacing, setGridSpacing] = useState(12);\n\n  // Once there are more than three people in a row we readjust the spacing.\n  useEffect(() => {\n    // Users.length + 1 to account for the user itself in the total count.\n    setGridSpacing(Math.max(Math.floor(12 / (users.length + 1)), 4));\n    // Only do this when the count of users changes or when the audio/video tracks change.\n  }, [users, tracks]);\n  \n  return (\n    // The Agora Video Player as the parent must have a height otherwise it defaults to 0% and the children containers won't be visible.\n    <Grid container style={{ height: \"100%\" }}>\n        {/* When the screen is XS then the grid item will take up the number of squares associated with the gridSpacing value from the state. */}\n      <Grid item xs={gridSpacing}>\n        {/* This is the client's video player. */}\n        <AgoraVideoPlayer\n          videoTrack={tracks[1]}\n          style={{ height: \"100%\", width: \"100%\" }}\n        />\n      </Grid>\n      {/* To create another video player for each participant in the call from the users state count. */}\n      {users.length > 0 &&\n        users.map((user) => {\n          console.log(\"USER ADDED:\", user);\n          if (user.videoTrack) {\n            return (\n              <Grid item xs={gridSpacing}>\n                <AgoraVideoPlayer\n                  videoTrack={user.videoTrack}\n                  key={user.uid}\n                  style={{ height: \"100%\", width: \"100%\" }}\n                />\n              </Grid>\n            );\n            // If we have no users then don't render anything.\n          } else return null;\n        })}\n    </Grid>\n  );\n}","import React from \"react\";\nimport { useState, useEffect } from 'react';\nimport { config, useClient, useMicrophoneAndCameraTracks, channelName } from \"./settings.js\";\nimport { Grid } from \"@material-ui/core\";\nimport Controls from './Controls.js';\nimport Video from './Video.js';\n\nexport default function VideoCall(props) {\n    const { setInCall } = props;\n    const [ users, setUsers ] = useState([]);\n    const [ start, setStart ] = useState(false);\n\n    // Returns to us a client object that allows us to connect to the video call.\n    const client = useClient();\n    // Gives us a video and audio track and whether they are ready to be used. Intialize audio/video. Handles asking the user for audio/video permissions.\n    const { ready, tracks } = useMicrophoneAndCameraTracks();\n\n    useEffect(() => {\n        let init = async (name) => {\n            // See here for implementing the channel logic for the event listeners for each client is listed below and in the documentation at this link: https://docs.agora.io/en/video-calling/get-started/get-started-sdk?platform=web\n            // If a user enables their mic or video they are publishing from a stream.\n            client.on(\"user-published\", async(user, mediaType) => {\n                await client.subscribe(user, mediaType);\n                if (mediaType === 'video') {\n                    // Get the previous users and add the new users.\n                    setUsers((prevUsers) => {\n                        return [...prevUsers, user];\n                    });\n                };\n                // Enable audio for the user.\n                if (mediaType === 'audio') {\n                    user.audioTrack.play();\n                };\n            });\n\n            // If a user disables their mic or video they are unpublishing from a stream.\n            client.on(\"user-unpublished\", (user, mediaType) => {\n                if (mediaType === 'audio') {\n                   if (user.audioTrack) user.audioTrack.stop();\n                };\n                if (mediaType === 'video') {\n                    // Remove the user from the users state once they unsubscribe from sharing their video.\n                    setUsers((prevUsers) => {\n                        // Create a new array of users that includes everyone but the user that unpublished.\n                        return prevUsers.filter((User) => User.uid !== user.uid)\n                    });\n                };\n            });\n\n            client.on(\"user-left\", (user) => {\n                // Same as above, if the user has left then remove them from the users state.\n                setUsers((prevUsers) => {\n                        return prevUsers.filter((User) => User.uid !== user.uid)\n                    });\n            });\n\n            try {\n                // The last argument is null to automatically generate an uid (unique ID) for the user joining the call.\n                await client.join(config.appId, name, config.token, null);\n            } catch (error) {\n                console.log(`Error: ${error}`)\n            }\n\n            // Check if we have any tracks, if we do then audio and video has been initialized.\n            if (tracks) await client.publish(tracks[0], tracks[1]);\n            setStart(true);\n        };\n\n        if (ready && tracks) {\n            try {\n                // We are trying to initialize the video stream with the given channel name from the Agora config, in this case it is \"main\".\n                init(channelName);\n            } catch (error) {\n                console.log(`Error: ${error}`)\n            }\n        }\n        // When any of the below changes the useEffect function will run.\n    }, [channelName, client, ready, tracks])\n\n    return (\n        // Use the MaterialUI grid layout to display.\n        <Grid container direction=\"column\" style={{ height: \"100%\" }}>\n            {/* Render the controls on screen. */}\n            <Grid item style={{ height: \"5%\" }}>\n                {/* We should only show controls for our video if our video is enabled and permissions are completed successfully. */}\n                {ready && tracks && (<Controls tracks={tracks} setStart={start} setInCall={setInCall} />\n                )}\n            </Grid>\n            {/* Render the video panel. */}\n             <Grid item style={{ height: \"95%\" }}>\n                {/* Start is telling us that we can now view other people's videos even though we may or may not have given permission to our video. */}\n                {start && tracks && (<Video tracks={tracks} users={users} />\n                )}\n            </Grid>\n        </Grid>\n    );\n};","import React from \"react\";\nimport { useState } from \"react\";\nimport { Button } from \"@material-ui/core\";\nimport VideoCall from \"./VideoCall\";\n\nfunction App() {\n  const [inCall, setInCall] = useState(false);\n\n  return (\n    <div className=\"App\" style={{ height: \"100%\" }}>\n       {/* A button to enter the video call room. */}\n      {inCall ? (\n        <VideoCall setInCall={setInCall} />\n      ) : (\n        <Button\n          variant=\"contained\"\n          color=\"primary\"\n          onClick={() => setInCall(true)}\n        >\n          Join Call\n        </Button>\n      )}\n    </div>\n  );\n}\n\nexport default App;","import React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport \"./app.css\";\nimport App from \"./App\";\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n);"],"sourceRoot":""}